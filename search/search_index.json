{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Pulsar Processing: MeerKAT documentation The following is documentation on how to process MeerKat pulsar observations, primarily on OzSTAR. If you have a problem feel free to raise an issue on the GitHub page or make a fork , make the changes yourself and make a pull request so we can implement them. Contents OzSTAR - How to load and use software on the OzSTAR supercomputer. Software Installation - How to install pulsar software. Command Examples - Examples of how to perform common tasks. MeerKAT Pulsar Summary - Overview of the pulsar observing and processing with MeerKAT. MeerPipe - Overview of the Nextflow pulsar processing pipeline. OzSTAR storage - Description of where data is stored and the directory structure. MeerTime Ephemerides and Templates - How to access the ephemerides and templates and how they were created","title":"Home"},{"location":"#pulsar-processing-meerkat-documentation","text":"The following is documentation on how to process MeerKat pulsar observations, primarily on OzSTAR. If you have a problem feel free to raise an issue on the GitHub page or make a fork , make the changes yourself and make a pull request so we can implement them.","title":"Pulsar Processing: MeerKAT documentation"},{"location":"#contents","text":"OzSTAR - How to load and use software on the OzSTAR supercomputer. Software Installation - How to install pulsar software. Command Examples - Examples of how to perform common tasks. MeerKAT Pulsar Summary - Overview of the pulsar observing and processing with MeerKAT. MeerPipe - Overview of the Nextflow pulsar processing pipeline. OzSTAR storage - Description of where data is stored and the directory structure. MeerTime Ephemerides and Templates - How to access the ephemerides and templates and how they were created","title":"Contents"},{"location":"command_examples/","text":"Command examples Examples of how to run common pulsar software and links to other documentation on their packages. TODO!","title":"Command examples"},{"location":"command_examples/#command-examples","text":"Examples of how to run common pulsar software and links to other documentation on their packages. TODO!","title":"Command examples"},{"location":"ephem_template/","text":"MeerTime Ephemerides and Templates The ephemerides and templates used by the different MeerTime project (PTA, TPA, RelBin and GC) are all stored in a private repository . Motivation The goal of this repository is to store all ephemerides and templates in one place to avoid duplication of work and make it clear how templates and ephemerides were created. Making the repository private prevents the values in the ephemerides being scoped by other researchers. It also allows control of the quality of ephemerides and templates by using automated testing of the files before they are pulled into the main branch and automated creation scripts to make the process more consistent. The central place will also make it easier for researchers in charge of rerunning processing pipelines to know when to reprocess pulsars and this may even be automated in the future. How to use Once the python scripts are installed you can return the path of the ephemeris for a particular pulsar and project (PTA, TPA, RelBin or GC) using: grab_ephemeris <pulsar> --project <project> This will grab a project specific ephemeris if it is available or the default ephemeris if it is not. You can use a similar command to grab the template and you can also specify the band (LBAND, UHF, SBAND_0, SBAND_1, SBAND_2, SBAND_3, SBAND_4) grab_template <pulsar> --project <project> --band <band> Layout The repository is layed out like so: . \u251c\u2500\u2500 ephem_template \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 python_grabber.py \u2502 \u251c\u2500\u2500 scripts \u2502 \u2502 \u251c\u2500\u2500 grab_ephemeris.py \u2502 \u2502 \u251c\u2500\u2500 grab_template.py \u2502 \u2502 \u2514\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 ephemeris \u2502 \u2502 \u251c\u2500\u2500 PTUSE \u2502 \u2502 \u2502 \u251c\u2500\u2500 J0437-4715.par \u2502 \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2502 \u2514\u2500\u2500 TPA \u2502 \u2502 \u251c\u2500\u2500 J0437-4715.par \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 template \u2502 \u251c\u2500\u2500 LBAND \u2502 \u2502 \u2514\u2500\u2500 TPA \u2502 \u2502 \u251c\u2500\u2500 J0437-4715.std \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 UHF \u2502 \u2514\u2500\u2500 TPA \u2502 \u251c\u2500\u2500 J0437-4715.std \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dev_scripts \u2502 \u2514\u2500\u2500 create_ephemeris.sh \u251c\u2500\u2500 README.md \u2514\u2500\u2500 setup.py The ephem_template/ephemeris directory contains the timing ephemerides split into project subdirectories The ephem_template/template directory contains the standard templates split into observing band subdirectories then project subdirectories The PTUSE project is not for a specific project and often has folding ephemerides taken from the raw archives with the vap -E command. The python scripts in ephem_template are simple scripts to decide which ephemeris or template to return based on the input pulsar name, project and observing band. The bash scripts in dev_scripts create or rename ephemerides and templates in a consistent way then put them into the correct directory to make development easier and more consistent. Development (add or update ephemerides and templates) To access the repository you must request to become a member of the GitHub team Meerkat Pulsar Timing by emailing Matthew Bailes or Nicholas Swainston. How to update the OzSTAR module is described in the repositories README.md","title":"MeerTime Ephemerides and Templates"},{"location":"ephem_template/#meertime-ephemerides-and-templates","text":"The ephemerides and templates used by the different MeerTime project (PTA, TPA, RelBin and GC) are all stored in a private repository .","title":"MeerTime Ephemerides and Templates"},{"location":"ephem_template/#motivation","text":"The goal of this repository is to store all ephemerides and templates in one place to avoid duplication of work and make it clear how templates and ephemerides were created. Making the repository private prevents the values in the ephemerides being scoped by other researchers. It also allows control of the quality of ephemerides and templates by using automated testing of the files before they are pulled into the main branch and automated creation scripts to make the process more consistent. The central place will also make it easier for researchers in charge of rerunning processing pipelines to know when to reprocess pulsars and this may even be automated in the future.","title":"Motivation"},{"location":"ephem_template/#how-to-use","text":"Once the python scripts are installed you can return the path of the ephemeris for a particular pulsar and project (PTA, TPA, RelBin or GC) using: grab_ephemeris <pulsar> --project <project> This will grab a project specific ephemeris if it is available or the default ephemeris if it is not. You can use a similar command to grab the template and you can also specify the band (LBAND, UHF, SBAND_0, SBAND_1, SBAND_2, SBAND_3, SBAND_4) grab_template <pulsar> --project <project> --band <band>","title":"How to use"},{"location":"ephem_template/#layout","text":"The repository is layed out like so: . \u251c\u2500\u2500 ephem_template \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 python_grabber.py \u2502 \u251c\u2500\u2500 scripts \u2502 \u2502 \u251c\u2500\u2500 grab_ephemeris.py \u2502 \u2502 \u251c\u2500\u2500 grab_template.py \u2502 \u2502 \u2514\u2500\u2500 __init__.py \u2502 \u251c\u2500\u2500 ephemeris \u2502 \u2502 \u251c\u2500\u2500 PTUSE \u2502 \u2502 \u2502 \u251c\u2500\u2500 J0437-4715.par \u2502 \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2502 \u2514\u2500\u2500 TPA \u2502 \u2502 \u251c\u2500\u2500 J0437-4715.par \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 template \u2502 \u251c\u2500\u2500 LBAND \u2502 \u2502 \u2514\u2500\u2500 TPA \u2502 \u2502 \u251c\u2500\u2500 J0437-4715.std \u2502 \u2502 \u2514\u2500\u2500 ... \u2502 \u2514\u2500\u2500 UHF \u2502 \u2514\u2500\u2500 TPA \u2502 \u251c\u2500\u2500 J0437-4715.std \u2502 \u2514\u2500\u2500 ... \u251c\u2500\u2500 dev_scripts \u2502 \u2514\u2500\u2500 create_ephemeris.sh \u251c\u2500\u2500 README.md \u2514\u2500\u2500 setup.py The ephem_template/ephemeris directory contains the timing ephemerides split into project subdirectories The ephem_template/template directory contains the standard templates split into observing band subdirectories then project subdirectories The PTUSE project is not for a specific project and often has folding ephemerides taken from the raw archives with the vap -E command. The python scripts in ephem_template are simple scripts to decide which ephemeris or template to return based on the input pulsar name, project and observing band. The bash scripts in dev_scripts create or rename ephemerides and templates in a consistent way then put them into the correct directory to make development easier and more consistent.","title":"Layout"},{"location":"ephem_template/#development-add-or-update-ephemerides-and-templates","text":"To access the repository you must request to become a member of the GitHub team Meerkat Pulsar Timing by emailing Matthew Bailes or Nicholas Swainston. How to update the OzSTAR module is described in the repositories README.md","title":"Development (add or update ephemerides and templates)"},{"location":"meerkat_pulsar_summary/","text":"MeerKAT Pulsar Processing Summary The following is a high level summary of how we turn radio waves into processed pulsar data displayed on the MeerTime Data Portal . This summary will include links to the other parts of this documentation and other resources that go into more detail of each aspect of the process. Many of these subsections will have one of the following labels to help you find the information you desire quicker: user : User documentation is for someone who wants to use the pipeline or webpages so needs to know how to load software, what options are available and where to find data. science : Scientist documentation is for someone who wants to understands the methods and math used in the process to increase their understanding or find potential issues dev : Developer documentation is for someone who wants to understand how the software works so they can add new features. The high level steps are the following: Observed with MeerKAT Preprocessed with the PTUSE Transferred to OzSTAR Observation metadata uploaded to MeerTime Data Portal Data processed using MeerPipe Observation results uploaded to MeerTime Data Portal The following documentation will go into more detail of each of these steps. Observed with MeerKAT The MeerKAT telescope is described in detail in the MeerKAT User Guide (user, science) and the the following papers (science): MeerKAT - The South African Array With Composite Dishes and Wide-Band Single Pixel Feeds The MeerKAT Radio Telescope The MeerKAT telescope as a pulsar facility: System verification and early science results from MeerTime Some of the methods and software used with MeerKAT are described in the engineering documentation (science, dev) . The MeerKat archive and other observing tools can be found in the SARAO apps web page (user) Preprocessed with the PTUSE The PTUSE is described in detail in The MeerKAT telescope as a pulsar facility: System verification and early science results from MeerTime . The PTUSE comprises of four servers (each server represents the beam ID in the observation metadata) which can be used to dedisperse and fold the data in real time. The PTUSE outputs archives in eight second sub-integrations which may have some timing smear in them due to the initial inaccurate ephemeris used during the observation. If you ever want to inspect the ephemeris used to create an archive file you can use the following command: vap -E <archive_file> MeerPipe MeerPipe is the Nextflow pipeline used to process MeerKAT pulsar data. It is described in detail in the MeerPipe documentation (user, science, dev) Transferred to OzSTAR The description of where the data is stored on OzSTAR can be found in the OzSTAR Storage (user) .","title":"MeerKAT Pulsar Processing Summary"},{"location":"meerkat_pulsar_summary/#meerkat-pulsar-processing-summary","text":"The following is a high level summary of how we turn radio waves into processed pulsar data displayed on the MeerTime Data Portal . This summary will include links to the other parts of this documentation and other resources that go into more detail of each aspect of the process. Many of these subsections will have one of the following labels to help you find the information you desire quicker: user : User documentation is for someone who wants to use the pipeline or webpages so needs to know how to load software, what options are available and where to find data. science : Scientist documentation is for someone who wants to understands the methods and math used in the process to increase their understanding or find potential issues dev : Developer documentation is for someone who wants to understand how the software works so they can add new features. The high level steps are the following: Observed with MeerKAT Preprocessed with the PTUSE Transferred to OzSTAR Observation metadata uploaded to MeerTime Data Portal Data processed using MeerPipe Observation results uploaded to MeerTime Data Portal The following documentation will go into more detail of each of these steps.","title":"MeerKAT Pulsar Processing Summary"},{"location":"meerkat_pulsar_summary/#observed-with-meerkat","text":"The MeerKAT telescope is described in detail in the MeerKAT User Guide (user, science) and the the following papers (science): MeerKAT - The South African Array With Composite Dishes and Wide-Band Single Pixel Feeds The MeerKAT Radio Telescope The MeerKAT telescope as a pulsar facility: System verification and early science results from MeerTime Some of the methods and software used with MeerKAT are described in the engineering documentation (science, dev) . The MeerKat archive and other observing tools can be found in the SARAO apps web page (user)","title":"Observed with MeerKAT"},{"location":"meerkat_pulsar_summary/#preprocessed-with-the-ptuse","text":"The PTUSE is described in detail in The MeerKAT telescope as a pulsar facility: System verification and early science results from MeerTime . The PTUSE comprises of four servers (each server represents the beam ID in the observation metadata) which can be used to dedisperse and fold the data in real time. The PTUSE outputs archives in eight second sub-integrations which may have some timing smear in them due to the initial inaccurate ephemeris used during the observation. If you ever want to inspect the ephemeris used to create an archive file you can use the following command: vap -E <archive_file>","title":"Preprocessed with the PTUSE"},{"location":"meerkat_pulsar_summary/#meerpipe","text":"MeerPipe is the Nextflow pipeline used to process MeerKAT pulsar data. It is described in detail in the MeerPipe documentation (user, science, dev)","title":"MeerPipe"},{"location":"meerkat_pulsar_summary/#transferred-to-ozstar","text":"The description of where the data is stored on OzSTAR can be found in the OzSTAR Storage (user) .","title":"Transferred to OzSTAR"},{"location":"meerpipe/","text":"MeerPipe TODO repo link","title":"MeerPipe"},{"location":"meerpipe/#meerpipe","text":"TODO repo link","title":"MeerPipe"},{"location":"ozstar/","text":"OzSTAR Guide The OzSTAR supercomputer is hosted by Swinburne university. It contains the original OzSTAR cluster and the new Ngarrgu Tindebeek (NT) cluster. Getting an account To gain an account, you can follow this guide . Once you have an account you should be able to join a project. The following projects relate to MeerKat pulsar astronomy: oz002 - General Swinburne pulsar work and Fast Radio Burst searches. oz005 - The MeerKAT Key Science Project on Pulsar Timing (MeerTime). oz242 - To search for relativistic pulsars in data from the 500m FAST telescope. Request to join all the projects that relate to your work. Loading pulsar software If you prefer the bash shell (the default) then add the following to your ~/.bashrc with your favorite test editor: source /fred/oz002/psrhome/scripts/psrhome.sh Then to load these changes run source ~/.bashrc to load these changes (this will be done by default when you log in) The common pulsar software is now loaded and ready for you to use. If you do not want to automatically load the common pulsar software or load a specific version instead, you can set up alias in your ~/.bashrc like so: # Load latest version of pulsar software alias psrhome=\"source /fred/oz002/psrhome/scripts/psrhome.sh\" # Load an older version of the pulsar software alias psr2023=\"module use /apps/users/pulsar/milan/gcc-11.3.0/modulefiles; module use /apps/users/pulsar/common/modulefiles; module load psrhome/2023-05\" # Load your python virtual environment alias venv=\"ml gcc/11.3.0 openmpi/4.1.4 python/3.10.4; source /dir/to/your/venv/bin/activate\" So now when you log in you can run psrhome to load pulsar software or venv if you want to do some python programming ( here is OzSTAR's virtual environment documentation). Loading pulsar software with tsch If you prefer the tsch shell (C shell) then add the following to your ~/.cshrc with your favorite test editor: source /fred/oz002/psrhome/scripts/psrhome.csh You can change your shell with changeShell command (see the docs )","title":"OzStar"},{"location":"ozstar/#ozstar-guide","text":"The OzSTAR supercomputer is hosted by Swinburne university. It contains the original OzSTAR cluster and the new Ngarrgu Tindebeek (NT) cluster.","title":"OzSTAR Guide"},{"location":"ozstar/#getting-an-account","text":"To gain an account, you can follow this guide . Once you have an account you should be able to join a project. The following projects relate to MeerKat pulsar astronomy: oz002 - General Swinburne pulsar work and Fast Radio Burst searches. oz005 - The MeerKAT Key Science Project on Pulsar Timing (MeerTime). oz242 - To search for relativistic pulsars in data from the 500m FAST telescope. Request to join all the projects that relate to your work.","title":"Getting an account"},{"location":"ozstar/#loading-pulsar-software","text":"If you prefer the bash shell (the default) then add the following to your ~/.bashrc with your favorite test editor: source /fred/oz002/psrhome/scripts/psrhome.sh Then to load these changes run source ~/.bashrc to load these changes (this will be done by default when you log in) The common pulsar software is now loaded and ready for you to use. If you do not want to automatically load the common pulsar software or load a specific version instead, you can set up alias in your ~/.bashrc like so: # Load latest version of pulsar software alias psrhome=\"source /fred/oz002/psrhome/scripts/psrhome.sh\" # Load an older version of the pulsar software alias psr2023=\"module use /apps/users/pulsar/milan/gcc-11.3.0/modulefiles; module use /apps/users/pulsar/common/modulefiles; module load psrhome/2023-05\" # Load your python virtual environment alias venv=\"ml gcc/11.3.0 openmpi/4.1.4 python/3.10.4; source /dir/to/your/venv/bin/activate\" So now when you log in you can run psrhome to load pulsar software or venv if you want to do some python programming ( here is OzSTAR's virtual environment documentation).","title":"Loading pulsar software"},{"location":"ozstar/#loading-pulsar-software-with-tsch","text":"If you prefer the tsch shell (C shell) then add the following to your ~/.cshrc with your favorite test editor: source /fred/oz002/psrhome/scripts/psrhome.csh You can change your shell with changeShell command (see the docs )","title":"Loading pulsar software with tsch"},{"location":"ozstar_storage/","text":"OzSTAR Storage The following is a description of where data is stored and the directory structure for the processed fold mode data , raw fold mode data and the raw search mode data . The following are used to describe the directory structure: <pulsar> : A pulsar J name (e.g. J0437-4715) <utc> : The start time of the observation in UTC and the format \"YYYY-MM-DD-HH:MM:SS.SS\" (e.g. 2023-12-11-03:23:30) <beam> : The beam ID (the PTUSE server, e.g. 4) <freq> : The centre frequency in MHz (e.g. 1284) Processed fold mode data The processed fold mode data is generated with MeerPipe using the raw fold mode data and is stored in the following directory: /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam> This directory will contain a results.json file which are outputs of MeerPipe calculations and either a cleaned/zapped ( <pulsar>_<utc>_zap.ar ) or raw ( <pulsar>_<utc>_raw.ar ) file if no template is available (templates are required for cleaning with MeerGuard ). If there is only a raw file you can either manually clean it with paz or pazi or add a template to the ephemeris and template repo so that the MeerPipe pipeline can clean it and create the following outputs. This directory also contains the following subdirectories that will be explained in the following subsections: images decimated timing scintillation Images The images directory ( /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam>/images/ ) contains all the images that will be uploaded to the MeerTime data portal . Each image will either start with cleaned or raw depending on whether the image was created from a cleaned/zapped or raw archive respectively. The images names and descriptions are listed below in the same order they appear on the data portal: {cleaned/raw}_profile_ftp.png : The polarisation pulse profile. {cleaned/raw}_profile_fts.png : The pulse profile. {cleaned/raw}_phase_time.png : The phase vs. time plot. {cleaned/raw}_phase_freq.png : The phase vs. frequency plot. {cleaned/raw}_bandpass.png : The bandpass plot which shows the frequency response and which channels were flagged. {cleaned/raw}_SNR_cumulative.png : The cumulative signal-to-noise ratio plot which shows how the SNR increases with time. {cleaned/raw}_SNR_single.png : The single subint signal-to-noise ratio plot which shows the SNR at each subint. Decimated The decimated directory ( /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam>/decimated/ ) contains the decimated archives that are used for the timing analysis for all projects. The decimated archives have the following naming convention: <pulsar>_<utc>_{zap/raw}<_chopped>.<nchan>ch_<npol>p_<nsub_type>_<nsub>t.ar where {zap/raw} represents if the archive was cleaned or not, <_chopped> is included in the file name if the edge frequency channels are removed, <nchan> is the number of frequency channels, <npol> is the number of polarisations, <nsub_type> is the method used to calculate the number of subintegrations (see next section ), and <nsub> is the number of time subintegrations. The following are examples of the decimated file names: J1744-1134_2019-10-05-11:17:35_zap_chopped.16ch_1p_1t.ar is a decimated cleaned archive with the edge channels removed, 16 frequency channels, 1 polarisation and 1 subintegration. Note that the 1 nsub type observations don't have both their <nsub_type> and <nsub> as they are both the same. J1744-1134_2019-10-05-11:17:35_zap_chopped.1ch_4p_all_32t.ar is a decimated cleaned archive with the edge channels removed, 1 frequency channel (frequency scrunched), full Stokes polarisations and all subintegrations (not time scrunched) which is 32 for this observation. J1744-1134_2019-10-05-11:17:35_raw_chopped.928ch_4p_mode_1t.ar is a decimated RAW archive with the edge channels removed, 928 frequency channels, full Stokes polarisations and mode subintegrations which is 1 for this observation. Note this is a raw archive so caution should be used when using it for sensitive science. Nsub types There are currently four methods of how to calculate how many time subintegrations to use for an observations which are listed below. \"1\": a single nsub (time scrunched) \"all\": all available nsubs (no time scrunching), only done for single nchan decimations (frequency scrunched) \"max\" the maximum number of subints possible for the observation based on the S/N ratio. The maximum is calculated using the meerpipe script calc_max_nsub which uses the logic: $$ nsub = \\left ( \\frac{S/N}{S/N_D} \\right )^2 \\frac{1}{nchan} $$ where \\(S/N\\) is the signal-to-noise ration of the observation, \\(S/N_D\\) is the desired signal-to-noise ratio of ToA (12 by default) and \\(nchan\\) is the number of frequency channels for this decimation. \"mode\" the length of each subintegration is equal to the most common observation duration. This value is calculated as part of the webportal query which rounds all values to the nearest 32 seconds and finds the most common duration, prioritising short observations in the case of a draw. Timing The timing directory contains subdirectories for each project (e.g PTA) ( /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam>/decimated/<project>/ ). In each of these project timing subdirectories there is a ephemeris file ( <pulsar>.par ) and a template file ( <pulsar>.std ) which are used to make a time of arrival (ToA) .tim files. The ToA files have the following format: <pulsar>_<utc>_zap<_chopped>.<nchan>ch_<npol>p_<nsub_type>_<nsub>.tim where, as above, <_chopped> is included in the file name if the edge frequency channels are removed, <nchan> is the number of frequency channels, <npol> is the number of polarisations, <nsub_type> is the method used to calculate the number of subintegrations (see previous section ), and <nsub> is the number of time subintegrations. The ToAs can manually be combined into a single .tim file or more easily downloaded using psrdb toa download , see the psrd docs for examples of how to do so. Scintillation The scintillation directory ( /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam>/scintillation/ ) contains files used for scintillation analysis. The .dynspec data files are generated with the psrflux psrchive script and have the following naming convention: <pulsar>_<utc>_{raw,zap}.ar.dynspec Where raw is for the raw archives and zap is for the cleaned/zapped archives. There are also png files which are created with the scintools repository and have the following naming convention: <pulsar>_<utc>_{raw,zap}.ar.dynspec.png Raw fold mode data The raw fold mode data is stored in the following directory: /fred/oz005/timing/<pulsar>/<utc>/<beam>/<freq> Which contains: *.ar : The raw fold mode archives in ~8 second sub-integrations. obs.header : The metadata file output by the PTUSE. meertime.json : The metadata file in the format required by the MeerTime data portal which was created by psrdb . obs.finished : Empty file that is used to indicate the observation has finished transferring to OzSTAR. Raw search mode data The raw search mode data is stored in the following directory: /fred/oz005/search/<pulsar>/<utc>/<beam>/<freq> Which contains: *.sf : The raw search mode archives in ~8 second sub-integrations. obs.header : The metadata file output by the PTUSE. meertime.json : The metadata file in the format required by the MeerTime data portal which was created by psrdb . obs.finished : Empty file that is used to indicate the observation has finished transferring to OzSTAR. transfer.list : List of files that have been transferred to OzSTAR.","title":"OzSTAR storage"},{"location":"ozstar_storage/#ozstar-storage","text":"The following is a description of where data is stored and the directory structure for the processed fold mode data , raw fold mode data and the raw search mode data . The following are used to describe the directory structure: <pulsar> : A pulsar J name (e.g. J0437-4715) <utc> : The start time of the observation in UTC and the format \"YYYY-MM-DD-HH:MM:SS.SS\" (e.g. 2023-12-11-03:23:30) <beam> : The beam ID (the PTUSE server, e.g. 4) <freq> : The centre frequency in MHz (e.g. 1284)","title":"OzSTAR Storage"},{"location":"ozstar_storage/#processed-fold-mode-data","text":"The processed fold mode data is generated with MeerPipe using the raw fold mode data and is stored in the following directory: /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam> This directory will contain a results.json file which are outputs of MeerPipe calculations and either a cleaned/zapped ( <pulsar>_<utc>_zap.ar ) or raw ( <pulsar>_<utc>_raw.ar ) file if no template is available (templates are required for cleaning with MeerGuard ). If there is only a raw file you can either manually clean it with paz or pazi or add a template to the ephemeris and template repo so that the MeerPipe pipeline can clean it and create the following outputs. This directory also contains the following subdirectories that will be explained in the following subsections: images decimated timing scintillation","title":"Processed fold mode data"},{"location":"ozstar_storage/#images","text":"The images directory ( /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam>/images/ ) contains all the images that will be uploaded to the MeerTime data portal . Each image will either start with cleaned or raw depending on whether the image was created from a cleaned/zapped or raw archive respectively. The images names and descriptions are listed below in the same order they appear on the data portal: {cleaned/raw}_profile_ftp.png : The polarisation pulse profile. {cleaned/raw}_profile_fts.png : The pulse profile. {cleaned/raw}_phase_time.png : The phase vs. time plot. {cleaned/raw}_phase_freq.png : The phase vs. frequency plot. {cleaned/raw}_bandpass.png : The bandpass plot which shows the frequency response and which channels were flagged. {cleaned/raw}_SNR_cumulative.png : The cumulative signal-to-noise ratio plot which shows how the SNR increases with time. {cleaned/raw}_SNR_single.png : The single subint signal-to-noise ratio plot which shows the SNR at each subint.","title":"Images"},{"location":"ozstar_storage/#decimated","text":"The decimated directory ( /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam>/decimated/ ) contains the decimated archives that are used for the timing analysis for all projects. The decimated archives have the following naming convention: <pulsar>_<utc>_{zap/raw}<_chopped>.<nchan>ch_<npol>p_<nsub_type>_<nsub>t.ar where {zap/raw} represents if the archive was cleaned or not, <_chopped> is included in the file name if the edge frequency channels are removed, <nchan> is the number of frequency channels, <npol> is the number of polarisations, <nsub_type> is the method used to calculate the number of subintegrations (see next section ), and <nsub> is the number of time subintegrations. The following are examples of the decimated file names: J1744-1134_2019-10-05-11:17:35_zap_chopped.16ch_1p_1t.ar is a decimated cleaned archive with the edge channels removed, 16 frequency channels, 1 polarisation and 1 subintegration. Note that the 1 nsub type observations don't have both their <nsub_type> and <nsub> as they are both the same. J1744-1134_2019-10-05-11:17:35_zap_chopped.1ch_4p_all_32t.ar is a decimated cleaned archive with the edge channels removed, 1 frequency channel (frequency scrunched), full Stokes polarisations and all subintegrations (not time scrunched) which is 32 for this observation. J1744-1134_2019-10-05-11:17:35_raw_chopped.928ch_4p_mode_1t.ar is a decimated RAW archive with the edge channels removed, 928 frequency channels, full Stokes polarisations and mode subintegrations which is 1 for this observation. Note this is a raw archive so caution should be used when using it for sensitive science.","title":"Decimated"},{"location":"ozstar_storage/#nsub-types","text":"There are currently four methods of how to calculate how many time subintegrations to use for an observations which are listed below. \"1\": a single nsub (time scrunched) \"all\": all available nsubs (no time scrunching), only done for single nchan decimations (frequency scrunched) \"max\" the maximum number of subints possible for the observation based on the S/N ratio. The maximum is calculated using the meerpipe script calc_max_nsub which uses the logic: $$ nsub = \\left ( \\frac{S/N}{S/N_D} \\right )^2 \\frac{1}{nchan} $$ where \\(S/N\\) is the signal-to-noise ration of the observation, \\(S/N_D\\) is the desired signal-to-noise ratio of ToA (12 by default) and \\(nchan\\) is the number of frequency channels for this decimation. \"mode\" the length of each subintegration is equal to the most common observation duration. This value is calculated as part of the webportal query which rounds all values to the nearest 32 seconds and finds the most common duration, prioritising short observations in the case of a draw.","title":"Nsub types"},{"location":"ozstar_storage/#timing","text":"The timing directory contains subdirectories for each project (e.g PTA) ( /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam>/decimated/<project>/ ). In each of these project timing subdirectories there is a ephemeris file ( <pulsar>.par ) and a template file ( <pulsar>.std ) which are used to make a time of arrival (ToA) .tim files. The ToA files have the following format: <pulsar>_<utc>_zap<_chopped>.<nchan>ch_<npol>p_<nsub_type>_<nsub>.tim where, as above, <_chopped> is included in the file name if the edge frequency channels are removed, <nchan> is the number of frequency channels, <npol> is the number of polarisations, <nsub_type> is the method used to calculate the number of subintegrations (see previous section ), and <nsub> is the number of time subintegrations. The ToAs can manually be combined into a single .tim file or more easily downloaded using psrdb toa download , see the psrd docs for examples of how to do so.","title":"Timing"},{"location":"ozstar_storage/#scintillation","text":"The scintillation directory ( /fred/oz005/users/nswainst/meerpipe_testing_outputs/<pulsar>/<utc>/<beam>/scintillation/ ) contains files used for scintillation analysis. The .dynspec data files are generated with the psrflux psrchive script and have the following naming convention: <pulsar>_<utc>_{raw,zap}.ar.dynspec Where raw is for the raw archives and zap is for the cleaned/zapped archives. There are also png files which are created with the scintools repository and have the following naming convention: <pulsar>_<utc>_{raw,zap}.ar.dynspec.png","title":"Scintillation"},{"location":"ozstar_storage/#raw-fold-mode-data","text":"The raw fold mode data is stored in the following directory: /fred/oz005/timing/<pulsar>/<utc>/<beam>/<freq> Which contains: *.ar : The raw fold mode archives in ~8 second sub-integrations. obs.header : The metadata file output by the PTUSE. meertime.json : The metadata file in the format required by the MeerTime data portal which was created by psrdb . obs.finished : Empty file that is used to indicate the observation has finished transferring to OzSTAR.","title":"Raw fold mode data"},{"location":"ozstar_storage/#raw-search-mode-data","text":"The raw search mode data is stored in the following directory: /fred/oz005/search/<pulsar>/<utc>/<beam>/<freq> Which contains: *.sf : The raw search mode archives in ~8 second sub-integrations. obs.header : The metadata file output by the PTUSE. meertime.json : The metadata file in the format required by the MeerTime data portal which was created by psrdb . obs.finished : Empty file that is used to indicate the observation has finished transferring to OzSTAR. transfer.list : List of files that have been transferred to OzSTAR.","title":"Raw search mode data"},{"location":"software_installation/","text":"Software installation The following documentation will explain how to install common pulsar software and some of the common problems you may encounter. Most of the time, it will be easier and more efficient to use the precompiled software on OzSTAR so this guide is only for those who want to install the software on a laptop or desktop for some quick local processing. Containers An easy and quick was to install software is to use a container. Have you ever been debugging software with someone and they say \"well it works on my machine\", containers tries reduce such problems by enabling you to virtually ship and entire computer (operating system and install software dependencies) to another user. These containers can be downloaded and run on your machine so the software is much more likely to behave in the same way. The two most common container software packages are Docker (for most computers) and Singularity/Apptainer (for use on supercomputers). If you are not doing large scale processing (hundreds of jobs) then a container may be all you need. The following are a list of pulsar software docker containers that may suit your needs psr-analysis ( repo ) (Tempo, Tempo2, PINT, psrcat, PSRCHIVE, DSPSR and PulsePortraiture) psr-search ( repo ) (Tempo, psrcat, PRESTO, and riptide (FFA)) presto ( repo ) General compiling tips Compilers output a huge amount of text and it can be hard to understand. If you're not even sure if it ran successfully, one thing you can do is check the exitcode with echo $? If it outputs 0 then it compiled successfully. All non-zero numbers are errorcodes which try to help describe what went wrong and mean it is time to debug. Some programs also come with tests so you can run make test and if the tests pass you can be even more confident that the software is install correctly. As you start debugging the compilation, it can be easier to pipe the output to a log file by adding >>& build.log to the end of the command like so make >>& build.log You can then search for error: to more easily find what the issue is. You should also check the outputs of ./bootstrap and ./configure as their main job is to find dependencies. So if the compiler is complaining about not finding software check the ./bootstrap and ./configure output. You should never copy the executable files (outputs of the compilers that you use to run code) or configure scripts from other computers/systems. These will have been compiled on a different systems so they will be built for different infrastructure and dependencies so they likely will not run on your system. To get software to compile you often have to add different compiler flags/options so they work for your dependencies and compiler versions. You can add these compiler flags using CFLAGS=<C flags here> for the gcc compiler, CXXFLAGS=<C++ flags here> for the c++ compiler and FFLAGS=<fortran flags here> for the gfortran compiler. There configure script offers many command line options for enabling/disabling features which you can check with the --help option. If the software has a configure script it is best to add the flags to the ./configure command as they will be appended to the other flags the configure script determines the compiler requires. So do this: ./configure CFLAGS=<C flags here> FFLAGS=<fortran flags here> make clean make not this: # BAD! DO NOT DO THIS ./configure make clean make CFLAGS=<C flags here> FFLAGS=<fortran flags here> as adding CFLAGS or FFLAGS to the make command may overwrite other compiler flags. Dependencies You will need to install the following packages with a package manager: build-essential autoconf autotools-dev automake autogen libtool pkg-config cmake csh g++ gcc gfortran wget git expect libcfitsio-dev hwloc perl pcre2-utils libpcre2-dev pgplot5 python3 python3-dev python3-testresources python3-pip python3-setuptools python3-tk libfftw3-3 libfftw3-bin libfftw3-dev libfftw3-single3 libx11-dev libpcre3 libpcre3-dev libpng-dev libpnglite-dev libhdf5-dev libhdf5-serial-dev libxml2 libxml2-dev libltdl-dev gsl-bin libgsl-dev libblas-dev liblapack-dev libglib2.0-dev xorg We will assume you are going to install this into a directory ASTROSOFT where you will run most of the following commands and install the software to. Define this location and other environmental variables by adding the following to your .bashrc (based on Lawrence Tommey's documentation ) # Path to the pulsar software installation directory e.g: export ASTROSOFT=/home/${USER}/pulsar_software # OSTYPE export OSTYPE=linux # PGPLOT this assumes you install pgplot5 using apt export PGPLOT_DIR=/usr/lib/pgplot5 # PSRCAT export PSRCAT_RUNDIR=$ASTROSOFT/psrcat_tar export PSRCAT_FILE=$ASTROSOFT/psrcat_tar/psrcat.db # Tempo export TEMPO=$ASTROSOFT/tempo # Tempo2 export TEMPO2=$ASTROSOFT/tempo2/T2runtime # PRESTO export PRESTO=$ASTROSOFT/presto # MULTINEST export MULTINEST_DIR=$ASTROSOFT/TempoNest/MultiNest # LD_LIBRARY_PATH export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib:/usr/lib/x86_64-linux-gnu:$PGPLOT_DIR:$ASTROSOFT/lib:$PRESTO/lib:$PRESTO/lib64:$MULTINEST_DIR # PATH # Some Presto executables match sigproc executables so keep separate - # all other executables are found in $ASTROSOFT/bin export PATH=$PATH:$ASTROSOFT/bin:$PRESTO/bin:$PGPLOT_DIR # PYTHON PATH eg. export PYTHONPATH=$PYTHONPATH:$PRESTO/lib/python3.10/site-packages:/usr/lib/python3.10/site-packages/:/usr/lib64/python3.10/site-packages:$ASTROSOFT/lib/python3.10/site-packages You may have to change the python version in the export PYTHONPATH command. For example if you use python version 3.9.6 (check with python -V ) then change python3.10 to python3.9 Installing in a debian OS (easy) If you would like to install this software on your personal computer (not a supercomputer) the following command will install the required dependencies on linux debian operating systems (Ubuntu, Mint, etc.). sudo apt install build-essential autoconf autotools-dev automake autogen libtool pkg-config cmake csh g++ gcc gfortran wget git expect libcfitsio-dev hwloc perl pcre2-utils libpcre2-dev pgplot5 python3 python3-dev python3-testresources python3-pip python3-setuptools python3-tk libfftw3-3 libfftw3-bin libfftw3-dev libfftw3-single3 libx11-dev libpcre3 libpcre3-dev libpng-dev libpnglite-dev libhdf5-dev libhdf5-serial-dev libxml2 libxml2-dev libltdl-dev gsl-bin libgsl-dev libblas-dev liblapack-dev xorg libglib2.0-dev Install manually (hard) If you would like to install these dependencies manually (because you are installing it on supercomputer perhaps) then the following sections will show you how install each dependency manually. FFTW If you want a different version you can find the tar for of it in their downloads page cd $ASTROSOFT wget https://fftw.org/pub/fftw/fftw-3.3.8.tar.gz tar -xzf fftw-3.3.8.tar.gz cd fftw-3.3.8 autoreconf --verbose --install --symlink --force ./configure --enable-shared --enable-float --enable-sse --disable-dependency-tracking --prefix=${ASTROSOFT} make clean make make install psrdada cd $ASTROSOFT git clone git://git.code.sf.net/p/psrdada/code psrdada cd psrdada ./bootstrap ./configure --prefix=${ASTROSOFT} make clean make make install make clean You may see an error that looks like this: ... multiple definition of ... first defined here collect2: error: ld returned 1 exit status This is due to new compilers (gcc version >9) not liking the old variable definition style. You can make it ignore these issues by adding a compiler option like so: ./configure CFLAGS=-fcommon make clean make pgplot cd $ASTROSOFT wget ftp://ftp.astro.caltech.edu/pub/pgplot/pgplot5.2.tar.gz tar -xzf pgplot5.2.tar.gz rm -r pgplot5.2.tar.gz cd pgplot sed -i \"s/g77/gfortran/\" sys_linux/g77_gcc.conf makemake ${ASTROSOFT}/pgplot linux g77_gcc make make cpg make clean Update your `~/.bashrc to include: export PGPLOT_DIR=${ASTROSOFT}/pgplot export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${ASTROSOFT}/pgplot Common pulsar software The following are the commands required to download and install common pulsar software. It is recomended to install them in the following order as some software (such as Tempo) are dependencies for other packages. psrcat cd $ASTROSOFT wget https://www.atnf.csiro.au/research/pulsar/psrcat/downloads/psrcat_pkg.tar.gz gunzip -c psrcat_pkg.tar.gz | tar xvf - cd psrcat_tar source makeit # Move the psrcat executable to the path: cp psrcat $ASTROSOFT/bin You may see an error that looks like this: ... multiple definition of ... first defined here collect2: error: ld returned 1 exit status This is due to new compilers (gcc version >9) not liking the old variable definition style. You can make it ignore these issues by adding a compiler option like so: sed -i 's&/usr/bin/gcc&/usr/bin/gcc -fcommon&g' makeit Then recompile (run source makeit again) tempo cd $ASTROSOFT git clone http://git.code.sf.net/p/tempo/tempo cd tempo ./prepare ./configure --prefix=$ASTROSOFT make make install tempo2 cd $ASTROSOFT git clone https://bitbucket.org/psrsoft/tempo2.git cd tempo2 ./bootstrap ./configure --prefix=${ASTROSOFT} make make install make plugins make plugins-install make clean psrchive cd $ASTROSOFT git clone git://git.code.sf.net/p/psrchive/code psrchive cd psrchive ./bootstrap ./configure --prefix=${ASTROSOFT} --enable-shared make make install make clean If you see an error that looks similar to: 1063 | CALL REGFA1(HEF,HMF2,XE2H,NMF2,0.001,NMF1,XE2,SCHALT,HMF1) | 2 ...... 1311 | CALL REGFA1(130.0,500.0,TI13,TI50,0.01,TI1,TEDER,SCHALT,HS) | 1 Error: Type mismatch between actual argument at (1) and actual argument at (2) (REAL(4)/INTEGER(4)). This is due to a type missmatch that modern gfortran compilers don't like, to ignore it run ./configure --prefix=${ASTROSOFT} --enable-shared FLAGS=\"-fallow-argument-mismatch\" make clean make make install make clean dspsr cd $ASTROSOFT git clone git://git.code.sf.net/p/dspsr/code dspsr cd dspsr ./bootstrap ./configure --prefix=${ASTROSOFT} make make install make clean If you see errors like this: error: call to non-'constexpr' function 'long int sysconf(int)' and error: size of array 'altStackMem' is not an integral constant-expression This is because it using a version of catch2 with a bug in it that can be fixed by running sed -i 's/constexpr static std::size_t sigStackSize = 32768 >= MINSIGSTKSZ ? 32768 : MINSIGSTKSZ;/constexpr static std::size_t sigStackSize = 32768;/' test/catch.hpp then recompiling (running the make commands again) sigproc cd $ASTROSOFT git clone https://github.com/SixByNine/sigproc.git cd sigproc ./bootstrap ./configure --prefix=${ASTROSOFT} F77=gfortran make make install make clean If you get an error like this ... multiple definition of ... first defined here collect2: error: ld returned 1 exit status it is the old gcc error again. Fix it like this ./configure --prefix=${ASTROSOFT} F77=gfortran CFLAGS=-fcommon make clean make make install make clean You may get an error like this Error: Rank mismatch between actual argument at (1) and actual argument at (2) (scalar and rank-1) You can make the compiler ignore this with the option -fallow-argument-mismatch by running make again like so ./configure --prefix=${ASTROSOFT} F77=gfortran CFLAGS=-fcommon FFLAGS=-fallow-argument-mismatch make clean make make install make clean If you get an error like this inject_pulsar.c:548:35: error: 'nprof' not specified in enclosing 'parallel' 548 | for(unsigned i=0; i < nprof;i++){ | ^ inject_pulsar.c:547:9: note: enclosing 'parallel' 547 | #pragma omp parallel for default(none) shared(subpulse_map) | ^~~ This is because some of the variables in the parallel for loop were not explictly labeled as private or shared. The easiest way to fix this is to turn off default(none) like so sed -i \"s/default(none)//\" src/inject_pulsar.c Then recompile presto To install the C stuff (python stuff is further down) cd $ASTROSOFT git clone https://github.com/scottransom/presto.git cd presto/src make prep make make clean If you see lots of undefined references starting with cpg like this: /usr/bin/ld: xyline.c:(.text+0x12ef): undefined reference to `cpgmtxt' /usr/bin/ld: xyline.c:(.text+0x132a): undefined reference to `cpgline' /usr/bin/ld: xyline.c:(.text+0x1334): undefined reference to `cpgslw' /usr/bin/ld: xyline.c:(.text+0x1359): undefined reference to `cpgiden' Then it is likely something wrong with your pgplot installation. Make sure your environment variable PGPLOT_DIR is pointing to the right place. Now install the python stuff as well cd $ASTROSOFT/presto python3 setup.py install --prefix=$PRESTO If when using some of the presto python packages you see an error like this: pkg_resources.DistributionNotFound: The 'pyslalib' distribution was not found and is required by presto Then you also need to install the pyslalib python pacakge like this pip install pyslalib","title":"Software Installation"},{"location":"software_installation/#software-installation","text":"The following documentation will explain how to install common pulsar software and some of the common problems you may encounter. Most of the time, it will be easier and more efficient to use the precompiled software on OzSTAR so this guide is only for those who want to install the software on a laptop or desktop for some quick local processing.","title":"Software installation"},{"location":"software_installation/#containers","text":"An easy and quick was to install software is to use a container. Have you ever been debugging software with someone and they say \"well it works on my machine\", containers tries reduce such problems by enabling you to virtually ship and entire computer (operating system and install software dependencies) to another user. These containers can be downloaded and run on your machine so the software is much more likely to behave in the same way. The two most common container software packages are Docker (for most computers) and Singularity/Apptainer (for use on supercomputers). If you are not doing large scale processing (hundreds of jobs) then a container may be all you need. The following are a list of pulsar software docker containers that may suit your needs psr-analysis ( repo ) (Tempo, Tempo2, PINT, psrcat, PSRCHIVE, DSPSR and PulsePortraiture) psr-search ( repo ) (Tempo, psrcat, PRESTO, and riptide (FFA)) presto ( repo )","title":"Containers"},{"location":"software_installation/#general-compiling-tips","text":"Compilers output a huge amount of text and it can be hard to understand. If you're not even sure if it ran successfully, one thing you can do is check the exitcode with echo $? If it outputs 0 then it compiled successfully. All non-zero numbers are errorcodes which try to help describe what went wrong and mean it is time to debug. Some programs also come with tests so you can run make test and if the tests pass you can be even more confident that the software is install correctly. As you start debugging the compilation, it can be easier to pipe the output to a log file by adding >>& build.log to the end of the command like so make >>& build.log You can then search for error: to more easily find what the issue is. You should also check the outputs of ./bootstrap and ./configure as their main job is to find dependencies. So if the compiler is complaining about not finding software check the ./bootstrap and ./configure output. You should never copy the executable files (outputs of the compilers that you use to run code) or configure scripts from other computers/systems. These will have been compiled on a different systems so they will be built for different infrastructure and dependencies so they likely will not run on your system. To get software to compile you often have to add different compiler flags/options so they work for your dependencies and compiler versions. You can add these compiler flags using CFLAGS=<C flags here> for the gcc compiler, CXXFLAGS=<C++ flags here> for the c++ compiler and FFLAGS=<fortran flags here> for the gfortran compiler. There configure script offers many command line options for enabling/disabling features which you can check with the --help option. If the software has a configure script it is best to add the flags to the ./configure command as they will be appended to the other flags the configure script determines the compiler requires. So do this: ./configure CFLAGS=<C flags here> FFLAGS=<fortran flags here> make clean make not this: # BAD! DO NOT DO THIS ./configure make clean make CFLAGS=<C flags here> FFLAGS=<fortran flags here> as adding CFLAGS or FFLAGS to the make command may overwrite other compiler flags.","title":"General compiling tips"},{"location":"software_installation/#dependencies","text":"You will need to install the following packages with a package manager: build-essential autoconf autotools-dev automake autogen libtool pkg-config cmake csh g++ gcc gfortran wget git expect libcfitsio-dev hwloc perl pcre2-utils libpcre2-dev pgplot5 python3 python3-dev python3-testresources python3-pip python3-setuptools python3-tk libfftw3-3 libfftw3-bin libfftw3-dev libfftw3-single3 libx11-dev libpcre3 libpcre3-dev libpng-dev libpnglite-dev libhdf5-dev libhdf5-serial-dev libxml2 libxml2-dev libltdl-dev gsl-bin libgsl-dev libblas-dev liblapack-dev libglib2.0-dev xorg We will assume you are going to install this into a directory ASTROSOFT where you will run most of the following commands and install the software to. Define this location and other environmental variables by adding the following to your .bashrc (based on Lawrence Tommey's documentation ) # Path to the pulsar software installation directory e.g: export ASTROSOFT=/home/${USER}/pulsar_software # OSTYPE export OSTYPE=linux # PGPLOT this assumes you install pgplot5 using apt export PGPLOT_DIR=/usr/lib/pgplot5 # PSRCAT export PSRCAT_RUNDIR=$ASTROSOFT/psrcat_tar export PSRCAT_FILE=$ASTROSOFT/psrcat_tar/psrcat.db # Tempo export TEMPO=$ASTROSOFT/tempo # Tempo2 export TEMPO2=$ASTROSOFT/tempo2/T2runtime # PRESTO export PRESTO=$ASTROSOFT/presto # MULTINEST export MULTINEST_DIR=$ASTROSOFT/TempoNest/MultiNest # LD_LIBRARY_PATH export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/lib:/usr/lib/x86_64-linux-gnu:$PGPLOT_DIR:$ASTROSOFT/lib:$PRESTO/lib:$PRESTO/lib64:$MULTINEST_DIR # PATH # Some Presto executables match sigproc executables so keep separate - # all other executables are found in $ASTROSOFT/bin export PATH=$PATH:$ASTROSOFT/bin:$PRESTO/bin:$PGPLOT_DIR # PYTHON PATH eg. export PYTHONPATH=$PYTHONPATH:$PRESTO/lib/python3.10/site-packages:/usr/lib/python3.10/site-packages/:/usr/lib64/python3.10/site-packages:$ASTROSOFT/lib/python3.10/site-packages You may have to change the python version in the export PYTHONPATH command. For example if you use python version 3.9.6 (check with python -V ) then change python3.10 to python3.9","title":"Dependencies"},{"location":"software_installation/#installing-in-a-debian-os-easy","text":"If you would like to install this software on your personal computer (not a supercomputer) the following command will install the required dependencies on linux debian operating systems (Ubuntu, Mint, etc.). sudo apt install build-essential autoconf autotools-dev automake autogen libtool pkg-config cmake csh g++ gcc gfortran wget git expect libcfitsio-dev hwloc perl pcre2-utils libpcre2-dev pgplot5 python3 python3-dev python3-testresources python3-pip python3-setuptools python3-tk libfftw3-3 libfftw3-bin libfftw3-dev libfftw3-single3 libx11-dev libpcre3 libpcre3-dev libpng-dev libpnglite-dev libhdf5-dev libhdf5-serial-dev libxml2 libxml2-dev libltdl-dev gsl-bin libgsl-dev libblas-dev liblapack-dev xorg libglib2.0-dev","title":"Installing in a debian OS (easy)"},{"location":"software_installation/#install-manually-hard","text":"If you would like to install these dependencies manually (because you are installing it on supercomputer perhaps) then the following sections will show you how install each dependency manually.","title":"Install manually (hard)"},{"location":"software_installation/#fftw","text":"If you want a different version you can find the tar for of it in their downloads page cd $ASTROSOFT wget https://fftw.org/pub/fftw/fftw-3.3.8.tar.gz tar -xzf fftw-3.3.8.tar.gz cd fftw-3.3.8 autoreconf --verbose --install --symlink --force ./configure --enable-shared --enable-float --enable-sse --disable-dependency-tracking --prefix=${ASTROSOFT} make clean make make install","title":"FFTW"},{"location":"software_installation/#psrdada","text":"cd $ASTROSOFT git clone git://git.code.sf.net/p/psrdada/code psrdada cd psrdada ./bootstrap ./configure --prefix=${ASTROSOFT} make clean make make install make clean You may see an error that looks like this: ... multiple definition of ... first defined here collect2: error: ld returned 1 exit status This is due to new compilers (gcc version >9) not liking the old variable definition style. You can make it ignore these issues by adding a compiler option like so: ./configure CFLAGS=-fcommon make clean make","title":"psrdada"},{"location":"software_installation/#pgplot","text":"cd $ASTROSOFT wget ftp://ftp.astro.caltech.edu/pub/pgplot/pgplot5.2.tar.gz tar -xzf pgplot5.2.tar.gz rm -r pgplot5.2.tar.gz cd pgplot sed -i \"s/g77/gfortran/\" sys_linux/g77_gcc.conf makemake ${ASTROSOFT}/pgplot linux g77_gcc make make cpg make clean Update your `~/.bashrc to include: export PGPLOT_DIR=${ASTROSOFT}/pgplot export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:${ASTROSOFT}/pgplot","title":"pgplot"},{"location":"software_installation/#common-pulsar-software","text":"The following are the commands required to download and install common pulsar software. It is recomended to install them in the following order as some software (such as Tempo) are dependencies for other packages.","title":"Common pulsar software"},{"location":"software_installation/#psrcat","text":"cd $ASTROSOFT wget https://www.atnf.csiro.au/research/pulsar/psrcat/downloads/psrcat_pkg.tar.gz gunzip -c psrcat_pkg.tar.gz | tar xvf - cd psrcat_tar source makeit # Move the psrcat executable to the path: cp psrcat $ASTROSOFT/bin You may see an error that looks like this: ... multiple definition of ... first defined here collect2: error: ld returned 1 exit status This is due to new compilers (gcc version >9) not liking the old variable definition style. You can make it ignore these issues by adding a compiler option like so: sed -i 's&/usr/bin/gcc&/usr/bin/gcc -fcommon&g' makeit Then recompile (run source makeit again)","title":"psrcat"},{"location":"software_installation/#tempo","text":"cd $ASTROSOFT git clone http://git.code.sf.net/p/tempo/tempo cd tempo ./prepare ./configure --prefix=$ASTROSOFT make make install","title":"tempo"},{"location":"software_installation/#tempo2","text":"cd $ASTROSOFT git clone https://bitbucket.org/psrsoft/tempo2.git cd tempo2 ./bootstrap ./configure --prefix=${ASTROSOFT} make make install make plugins make plugins-install make clean","title":"tempo2"},{"location":"software_installation/#psrchive","text":"cd $ASTROSOFT git clone git://git.code.sf.net/p/psrchive/code psrchive cd psrchive ./bootstrap ./configure --prefix=${ASTROSOFT} --enable-shared make make install make clean If you see an error that looks similar to: 1063 | CALL REGFA1(HEF,HMF2,XE2H,NMF2,0.001,NMF1,XE2,SCHALT,HMF1) | 2 ...... 1311 | CALL REGFA1(130.0,500.0,TI13,TI50,0.01,TI1,TEDER,SCHALT,HS) | 1 Error: Type mismatch between actual argument at (1) and actual argument at (2) (REAL(4)/INTEGER(4)). This is due to a type missmatch that modern gfortran compilers don't like, to ignore it run ./configure --prefix=${ASTROSOFT} --enable-shared FLAGS=\"-fallow-argument-mismatch\" make clean make make install make clean","title":"psrchive"},{"location":"software_installation/#dspsr","text":"cd $ASTROSOFT git clone git://git.code.sf.net/p/dspsr/code dspsr cd dspsr ./bootstrap ./configure --prefix=${ASTROSOFT} make make install make clean If you see errors like this: error: call to non-'constexpr' function 'long int sysconf(int)' and error: size of array 'altStackMem' is not an integral constant-expression This is because it using a version of catch2 with a bug in it that can be fixed by running sed -i 's/constexpr static std::size_t sigStackSize = 32768 >= MINSIGSTKSZ ? 32768 : MINSIGSTKSZ;/constexpr static std::size_t sigStackSize = 32768;/' test/catch.hpp then recompiling (running the make commands again)","title":"dspsr"},{"location":"software_installation/#sigproc","text":"cd $ASTROSOFT git clone https://github.com/SixByNine/sigproc.git cd sigproc ./bootstrap ./configure --prefix=${ASTROSOFT} F77=gfortran make make install make clean If you get an error like this ... multiple definition of ... first defined here collect2: error: ld returned 1 exit status it is the old gcc error again. Fix it like this ./configure --prefix=${ASTROSOFT} F77=gfortran CFLAGS=-fcommon make clean make make install make clean You may get an error like this Error: Rank mismatch between actual argument at (1) and actual argument at (2) (scalar and rank-1) You can make the compiler ignore this with the option -fallow-argument-mismatch by running make again like so ./configure --prefix=${ASTROSOFT} F77=gfortran CFLAGS=-fcommon FFLAGS=-fallow-argument-mismatch make clean make make install make clean If you get an error like this inject_pulsar.c:548:35: error: 'nprof' not specified in enclosing 'parallel' 548 | for(unsigned i=0; i < nprof;i++){ | ^ inject_pulsar.c:547:9: note: enclosing 'parallel' 547 | #pragma omp parallel for default(none) shared(subpulse_map) | ^~~ This is because some of the variables in the parallel for loop were not explictly labeled as private or shared. The easiest way to fix this is to turn off default(none) like so sed -i \"s/default(none)//\" src/inject_pulsar.c Then recompile","title":"sigproc"},{"location":"software_installation/#presto","text":"To install the C stuff (python stuff is further down) cd $ASTROSOFT git clone https://github.com/scottransom/presto.git cd presto/src make prep make make clean If you see lots of undefined references starting with cpg like this: /usr/bin/ld: xyline.c:(.text+0x12ef): undefined reference to `cpgmtxt' /usr/bin/ld: xyline.c:(.text+0x132a): undefined reference to `cpgline' /usr/bin/ld: xyline.c:(.text+0x1334): undefined reference to `cpgslw' /usr/bin/ld: xyline.c:(.text+0x1359): undefined reference to `cpgiden' Then it is likely something wrong with your pgplot installation. Make sure your environment variable PGPLOT_DIR is pointing to the right place. Now install the python stuff as well cd $ASTROSOFT/presto python3 setup.py install --prefix=$PRESTO If when using some of the presto python packages you see an error like this: pkg_resources.DistributionNotFound: The 'pyslalib' distribution was not found and is required by presto Then you also need to install the pyslalib python pacakge like this pip install pyslalib","title":"presto"}]}